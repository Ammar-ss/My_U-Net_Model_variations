{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**CONFIGURATION**\n\nThis file holds all the configurable parameters, making it easy to tweak things without digging through the code.","metadata":{}},{"cell_type":"code","source":"# This is a centralized configuration file for the project.\n# All hyperparameters and paths are defined here for easy access and modification.\n\nclass Config:\n    # Data Parameters for Kaggle Environment\n    DATA_DIR = \"/kaggle/input/fetal-head-ultrasound-dataset-for-image-segment/\"\n    \n    # Image Dimensions\n    IMG_HEIGHT = 256\n    IMG_WIDTH = 256\n    IMG_CHANNELS = 3\n\n    # Training Hyperparameters\n    EPOCHS = 50\n    BATCH_SIZE = 8\n    LEARNING_RATE = 1e-4\n\n    # Model & Reproducibility\n    RANDOM_SEED = 42\n    # PyTorch models are typically saved with a .pth or .pt extension\n    MODEL_SAVE_PATH = \"/kaggle/working/AttentionUNet_PyTorch.pth\"\n    \n    # Specify number of classes for the model output\n    NUM_CLASSES = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**DATA LOADER**\n\nThis module handles all aspects of data loading, preprocessing, and splitting.","metadata":{}},{"cell_type":"code","source":"# This module handles data loading and preprocessing using PyTorch's Dataset and DataLoader.\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_data_paths_and_split(config):\n    \"\"\"Reads CSV, creates full paths, and splits data.\"\"\"\n    df = pd.read_csv(os.path.join(config.DATA_DIR, 'data.csv'))\n    df['image_path'] = df['Image'].apply(lambda x: os.path.join(config.DATA_DIR, x))\n    df['mask_path'] = df['Mask'].apply(lambda x: os.path.join(config.DATA_DIR, x))\n    \n    train_df, test_df = train_test_split(df, test_size=0.2, random_state=config.RANDOM_SEED)\n    train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=config.RANDOM_SEED)\n    \n    print(f\"\\nDataset Split:\")\n    print(f\"Training samples:   {len(train_df)}\")\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Test samples:       {len(test_df)}\")\n    \n    return train_df, val_df, test_df\n\nclass FetalHeadDataset(Dataset):\n    \"\"\"Custom PyTorch Dataset for fetal head ultrasound images.\"\"\"\n    def __init__(self, dataframe, transforms=None):\n        self.df = dataframe\n        self.transforms = transforms\n        self.image_paths = dataframe['image_path'].values\n        self.mask_paths = dataframe['mask_path'].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n        \n        # Load image and mask as numpy arrays\n        image = np.array(Image.open(image_path).convert(\"RGB\"))\n        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n        \n        # Binarize mask\n        mask[mask > 0] = 1.0\n        \n        if self.transforms:\n            augmented = self.transforms(image=image, mask=mask)\n            image = augmented['image']\n            mask = augmented['mask']\n            # Add channel dimension to mask: (H, W) -> (1, H, W)\n            mask = mask.unsqueeze(0)\n            \n        return image, mask\n\ndef get_loaders(config):\n    \"\"\"Creates and returns the training, validation, and test DataLoaders.\"\"\"\n    train_df, val_df, test_df = get_data_paths_and_split(config)\n    \n    # Define augmentations and transformations\n    # ToTensorV2 handles normalization if mean/std are provided and converts to tensor\n    train_transforms = A.Compose([\n        A.Resize(height=config.IMG_HEIGHT, width=config.IMG_WIDTH),\n        A.Rotate(limit=35, p=0.5),\n        A.HorizontalFlip(p=0.5),\n        A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n        ToTensorV2(),\n    ])\n    \n    val_test_transforms = A.Compose([\n        A.Resize(height=config.IMG_HEIGHT, width=config.IMG_WIDTH),\n        A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n        ToTensorV2(),\n    ])\n    \n    train_dataset = FetalHeadDataset(train_df, transforms=train_transforms)\n    val_dataset = FetalHeadDataset(val_df, transforms=val_test_transforms)\n    test_dataset = FetalHeadDataset(test_df, transforms=val_test_transforms)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n    \n    return train_loader, val_loader, test_loader\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**TRAINING THE MODEL**\n\nThis module contains the core training and validation loops.","metadata":{}},{"cell_type":"code","source":"# This module manages the model training and validation loops.\n\nimport torch\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom model_pytorch import criterion, dice_coeff\n\ndef train_one_epoch(loader, model, optimizer, device):\n    \"\"\"Runs a single training epoch.\"\"\"\n    model.train()\n    loop = tqdm(loader, leave=True)\n    running_loss = 0.0\n    \n    for batch_idx, (data, targets) in enumerate(loop):\n        data, targets = data.to(device), targets.to(device)\n        \n        # Forward pass\n        predictions = model(data)\n        loss = criterion(predictions, targets)\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n        \n    return running_loss / len(loader)\n\ndef validate(loader, model, device):\n    \"\"\"Evaluates the model on the validation set.\"\"\"\n    model.eval()\n    total_dice_score = 0\n    total_loss = 0\n    \n    with torch.no_grad():\n        for data, targets in loader:\n            data, targets = data.to(device), targets.to(device)\n            predictions = model(data)\n            \n            # Calculate loss\n            loss = criterion(predictions, targets)\n            total_loss += loss.item()\n            \n            # Calculate metrics\n            preds_sig = torch.sigmoid(predictions)\n            preds_binary = (preds_sig > 0.5).float()\n            total_dice_score += dice_coeff(preds_binary, targets)\n\n    avg_loss = total_loss / len(loader)\n    avg_dice = total_dice_score / len(loader)\n    \n    print(f\"Validation -> Avg Loss: {avg_loss:.4f}, Avg Dice Score: {avg_dice:.4f}\")\n    return avg_loss, avg_dice\n\ndef train_model(config, model, train_loader, val_loader, device):\n    \"\"\"The main training function.\"\"\"\n    print(\"\\n--- Starting Model Training ---\")\n    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.1, verbose=True)\n    \n    best_val_dice = -1.0\n    history = {'train_loss': [], 'val_loss': [], 'val_dice': []}\n\n    for epoch in range(config.EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{config.EPOCHS}\")\n        \n        train_loss = train_one_epoch(train_loader, model, optimizer, device)\n        val_loss, val_dice = validate(val_loader, model, device)\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_dice'].append(val_dice.item())\n        \n        # Update learning rate scheduler\n        scheduler.step(val_dice)\n        \n        # Save the best model\n        if val_dice > best_val_dice:\n            best_val_dice = val_dice\n            torch.save(model.state_dict(), config.MODEL_SAVE_PATH)\n            print(f\"-> New best model saved with Dice Score: {val_dice:.4f}\")\n            \n    return model, history\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**EVALUATION**\n\nThis module will calculate all the final metrics on the test set.","metadata":{}},{"cell_type":"code","source":"# This cell handles model evaluation on the test set and generates a results table.\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport cv2\nfrom scipy.spatial.distance import directed_hausdorff\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\nfrom tqdm import tqdm\nfrom model_pytorch import dice_coeff\n\ndef calculate_surface_distances(true_mask, pred_mask):\n    \"\"\"Calculates Hausdorff Distance and ASD.\"\"\"\n    # Squeeze to remove channel dim and convert to uint8\n    true_mask_u8 = true_mask.squeeze().astype(np.uint8)\n    pred_mask_u8 = pred_mask.squeeze().astype(np.uint8)\n    \n    true_contours, _ = cv2.findContours(true_mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    pred_contours, _ = cv2.findContours(pred_mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    \n    if not true_contours or not pred_contours: return np.nan, np.nan\n    \n    true_points = np.squeeze(true_contours[0])\n    pred_points = np.squeeze(pred_contours[0])\n    \n    if len(true_points.shape) < 2 or len(pred_points.shape) < 2: return np.nan, np.nan\n    \n    hd1 = directed_hausdorff(true_points, pred_points)[0]\n    hd2 = directed_hausdorff(pred_points, true_points)[0]\n    hausdorff_dist = max(hd1, hd2)\n    \n    dists_t_to_p = np.array([cv2.pointPolygonTest(pred_contours[0], tuple(pt), True) for pt in true_points])\n    dists_p_to_t = np.array([cv2.pointPolygonTest(true_contours[0], tuple(pt), True) for pt in pred_points])\n    asd = (np.mean(np.abs(dists_t_to_p)) + np.mean(np.abs(dists_p_to_t))) / 2.0\n    return hausdorff_dist, asd\n\ndef evaluate_model(model, loader, device):\n    \"\"\"Evaluates the model on a given dataset and returns a results DataFrame.\"\"\"\n    print(\"\\n--- Starting Comprehensive Model Evaluation ---\")\n    model.eval()\n    results = []\n    \n    with torch.no_grad():\n        for data, targets in tqdm(loader, \"Evaluating\"):\n            data, targets = data.to(device), targets.to(device)\n            preds_logits = model(data)\n            preds_sig = torch.sigmoid(preds_logits)\n            preds_binary = (preds_sig > 0.5).float()\n            \n            # Move tensors to CPU and convert to numpy for sklearn/scipy metrics\n            targets_np = targets.cpu().numpy()\n            preds_binary_np = preds_binary.cpu().numpy()\n            \n            for i in range(targets_np.shape[0]):\n                tm, pm = targets_np[i], preds_binary_np[i]\n                tm_flat, pm_flat = tm.flatten(), pm.flatten()\n                \n                hd, asd = calculate_surface_distances(tm, pm)\n                results.append({\n                    \"Accuracy\": accuracy_score(tm_flat, pm_flat),\n                    \"Precision\": precision_score(tm_flat, pm_flat, zero_division=0),\n                    \"Recall\": recall_score(tm_flat, pm_flat, zero_division=0),\n                    \"F1-Score\": f1_score(tm_flat, pm_flat, zero_division=0),\n                    \"Dice-Coefficient\": dice_coeff(preds_binary[i], targets[i]).item(),\n                    \"IoU\": jaccard_score(tm_flat, pm_flat, zero_division=0),\n                    \"Hausdorff-Distance\": hd,\n                    \"ASD\": asd\n                })\n\n    results_df = pd.DataFrame(results).dropna()\n    return results_df\n\ndef display_results_table(results_df):\n    \"\"\"Prints a publication-ready table of evaluation metrics.\"\"\"\n    summary_stats = results_df.agg(['mean', 'std']).T\n    summary_stats.columns = ['Mean', 'Standard Deviation']\n    summary_stats['Mean ± SD'] = summary_stats.apply(lambda row: f\"{row['Mean']:.4f} ± {row['Standard Deviation']:.4f}\", axis=1)\n    print(\"\\n--- Quantitative Evaluation Results ---\")\n    print(summary_stats[['Mean ± SD']])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**VISUALIZATION**\n\nThis module visualizes all the data","metadata":{}},{"cell_type":"code","source":"# Contains all functions for visualizing results.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport torch\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_learning_curves(history):\n    plt.figure(figsize=(18, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(history['val_dice'], label='Validation Dice Coef')\n    plt.title('Validation Dice Coefficient vs. Epochs'); plt.ylabel('Dice Coefficient'); plt.xlabel('Epoch'); plt.legend(loc='best')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history['train_loss'], label='Train Loss')\n    plt.plot(history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss vs. Epochs'); plt.ylabel('Loss'); plt.xlabel('Epoch'); plt.legend(loc='best')\n    plt.show()\n\ndef visualize_predictions(model, loader, device, num_samples=5):\n    model.eval()\n    images, masks = next(iter(loader))\n    images, masks = images.to(device), masks.to(device)\n    \n    with torch.no_grad():\n        preds_logits = model(images)\n        preds = torch.sigmoid(preds_logits) > 0.5\n\n    # Move to CPU and convert to numpy for plotting\n    images = images.cpu().numpy()\n    masks = masks.cpu().numpy()\n    preds = preds.cpu().numpy()\n\n    plt.figure(figsize=(15, 5 * num_samples))\n    for i in range(num_samples):\n        # Transpose image from (C, H, W) to (H, W, C) for display\n        img_to_show = np.transpose(images[i], (1, 2, 0))\n        \n        plt.subplot(num_samples, 3, i*3 + 1); plt.imshow(img_to_show); plt.title(\"Original Image\"); plt.axis('off')\n        plt.subplot(num_samples, 3, i*3 + 2); plt.imshow(masks[i].squeeze(), cmap='gray'); plt.title(\"Ground Truth\"); plt.axis('off')\n        plt.subplot(num_samples, 3, i*3 + 3); plt.imshow(img_to_show); plt.imshow(preds[i].squeeze(), cmap='jet', alpha=0.5); plt.title(\"Predicted Overlay\"); plt.axis('off')\n    \n    plt.tight_layout(); plt.show()\n\ndef plot_eval_graphics(results_df):\n    plt.figure(figsize=(15, 10))\n    plt.subplot(2, 2, 1); sns.boxplot(data=results_df[['Dice-Coefficient', 'IoU']], palette=\"viridis\"); plt.title('Distribution of Segmentation Metrics'); plt.ylabel('Score')\n    plt.subplot(2, 2, 2); sns.boxplot(data=results_df[['Hausdorff-Distance', 'ASD']], palette=\"plasma\"); plt.title('Distribution of Boundary Error Metrics'); plt.ylabel('Pixel Distance')\n    plt.tight_layout(); plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**MAIN FILE (BASE CLASS)**\n\nWell,this is your PUBLIC STATIC VOID MAIN() ","metadata":{}},{"cell_type":"code","source":"# Main function to run the entire thing.\n\nimport torch\nimport numpy as np\nfrom config_pytorch import Config\nfrom data_loader_pytorch import get_loaders\nfrom model_pytorch import AttentionUNet\nfrom train_pytorch import train_model\nfrom evaluate_pytorch import evaluate_model, display_results_table\nfrom visualize_pytorch import plot_learning_curves, visualize_predictions, plot_eval_graphics\n\ndef run_pipeline():\n    \"\"\"Executes the complete training and evaluation pipeline using PyTorch.\"\"\"\n    \n    # 1. Configuration and Setup\n    config = Config()\n    np.random.seed(config.RANDOM_SEED)\n    torch.manual_seed(config.RANDOM_SEED)\n    torch.cuda.manual_seed(config.RANDOM_SEED)\n    \n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Using device: {DEVICE}\")\n\n    # 2. Prepare DataLoaders\n    train_loader, val_loader, test_loader = get_loaders(config)\n    \n    # 3. Initialize Model\n    model = AttentionUNet(n_channels=config.IMG_CHANNELS, n_classes=config.NUM_CLASSES).to(DEVICE)\n    \n    # 4. Train Model\n    # Set to True to load a pre-trained model instead of training\n    LOAD_PRETRAINED = False\n    if LOAD_PRETRAINED:\n        model.load_state_dict(torch.load(config.MODEL_SAVE_PATH))\n        history = None # No history if not training\n    else:\n        model, history = train_model(config, model, train_loader, val_loader, DEVICE)\n\n    # 5. Evaluate Model\n    results_df = evaluate_model(model, test_loader, DEVICE)\n    display_results_table(results_df)\n    \n    # 6. Visualize Results\n    print(\"\\n--- Generating Visualizations ---\")\n    if history:\n        plot_learning_curves(history)\n    visualize_predictions(model, test_loader, DEVICE)\n    plot_eval_graphics(results_df)\n\nif __name__ == '__main__':\n    run_pipeline()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}